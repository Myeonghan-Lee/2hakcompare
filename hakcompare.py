import streamlit as st
import pandas as pd
import re
import io
import itertools

# -----------------------------------------------------------------------------
# 0. í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# -----------------------------------------------------------------------------
st.set_page_config(page_title="í•™ìƒë¶€ ì ê²€ ë„ìš°ë¯¸", layout="wide")

# -----------------------------------------------------------------------------
# 1. ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# -----------------------------------------------------------------------------

def load_data(uploaded_file):
    """íŒŒì¼ ë¡œë“œ (CSV, Excel)"""
    file_ext = uploaded_file.name.split('.')[-1].lower()
    try:
        if file_ext == 'csv':
            return pd.read_csv(uploaded_file, header=None)
        elif file_ext in ['xlsx', 'xls']:
            return pd.read_excel(uploaded_file, header=None, engine='openpyxl')
        else:
            return None
    except Exception as e:
        st.error(f"íŒŒì¼ ì˜¤ë¥˜ ({uploaded_file.name}): {e}")
        return None

def extract_grade_class(df_raw):
    """í•™ë…„ ë°˜ ì¶”ì¶œ"""
    limit = min(20, len(df_raw))
    for i in range(limit):
        row_values = df_raw.iloc[i].astype(str).values
        for val in row_values:
            match = re.search(r"(\d+)í•™ë…„\s*(\d+)ë°˜", val)
            if match:
                return match.group(0)
    return "ë¯¸ìƒ"

def detect_file_type(df_raw):
    """íŒŒì¼ ìœ í˜• ê°ì§€ (í–‰íŠ¹ / ì„¸íŠ¹ / ì°½ì²´)"""
    limit = min(20, len(df_raw))
    text_sample = df_raw.iloc[:limit].astype(str).to_string()
    
    if "ì°½ì˜ì " in text_sample and ("ì²´í—˜í™œë™" in text_sample or "ììœ¨" in text_sample):
        return "CHANG"
    elif "í–‰ ë™ íŠ¹ ì„±" in text_sample or "í–‰ë™íŠ¹ì„±" in text_sample or "ì¢…í•©ì˜ê²¬" in text_sample:
        return "HANG"
    elif "ì„¸ë¶€ëŠ¥ë ¥" in text_sample or "íŠ¹ê¸°ì‚¬í•­" in text_sample or "ê³¼ ëª©" in text_sample:
        return "KYO"
    else:
        return "UNKNOWN"

# -----------------------------------------------------------------------------
# 2. ë°ì´í„° ì²˜ë¦¬ ë¡œì§ (í–‰íŠ¹ / ì„¸íŠ¹ / ì°½ì²´)
# -----------------------------------------------------------------------------

def process_hang(df_raw, grade_class):
    header_idx = -1
    for i, row in df_raw.iterrows():
        row_str = row.astype(str).values
        if any('ë²ˆ' in s and 'í˜¸' in s for s in row_str) and any('ì„±' in s and 'ëª…' in s for s in row_str):
            header_idx = i
            break
    
    if header_idx == -1: return None

    df = df_raw.iloc[header_idx+1:].copy()
    df.columns = df_raw.iloc[header_idx].astype(str).str.replace(" ", "")
    
    rename_map = {}
    for col in df.columns:
        if 'ë²ˆí˜¸' in col: rename_map[col] = 'ë²ˆí˜¸'
        elif 'í–‰ë™íŠ¹ì„±' in col: rename_map[col] = 'ë‚´ìš©'
        elif 'ì¢…í•©ì˜ê²¬' in col: rename_map[col] = 'ë‚´ìš©'
    df = df.rename(columns=rename_map)
    
    if 'ë²ˆí˜¸' not in df.columns or 'ë‚´ìš©' not in df.columns: return None
        
    df['ë²ˆí˜¸'] = pd.to_numeric(df['ë²ˆí˜¸'], errors='coerce')
    df = df[df['ë‚´ìš©'].notna()]
    df = df[~df['ë‚´ìš©'].str.contains('í–‰ ë™ íŠ¹ ì„±', na=False)]
    df = df[~df['ë‚´ìš©'].str.contains('ì¢… í•© ì˜ ê²¬', na=False)]
    
    df['ë²ˆí˜¸'] = df['ë²ˆí˜¸'].ffill()
    df = df.dropna(subset=['ë²ˆí˜¸'])
    
    df_grouped = df.groupby('ë²ˆí˜¸')['ë‚´ìš©'].apply(lambda x: ' '.join(x.astype(str))).reset_index()
    
    df_grouped['í•™ë…„ ë°˜'] = grade_class
    df_grouped['í•™ê¸°'] = ''
    df_grouped['ê³¼ëª©/ì˜ì—­'] = 'í–‰ë™íŠ¹ì„±'
    df_grouped['ì‹œìˆ˜'] = ''
    
    return df_grouped[['í•™ë…„ ë°˜', 'ë²ˆí˜¸', 'í•™ê¸°', 'ê³¼ëª©/ì˜ì—­', 'ì‹œìˆ˜', 'ë‚´ìš©']]

def process_kyo(df_raw, grade_class):
    header_idx = -1
    for i, row in df_raw.iterrows():
        row_str = row.astype(str).values
        if any('ê³¼' in s and 'ëª©' in s for s in row_str) and any('ì„¸ë¶€ëŠ¥ë ¥' in s for s in row_str):
            header_idx = i
            break
            
    if header_idx == -1: return None
        
    df = df_raw.iloc[header_idx+1:].copy()
    df.columns = df_raw.iloc[header_idx].astype(str).str.replace(" ", "")
    
    rename_map = {}
    for col in df.columns:
        if 'ê³¼ëª©' in col: rename_map[col] = 'ê³¼ëª©/ì˜ì—­'
        elif 'í•™ê¸°' in col: rename_map[col] = 'í•™ê¸°'
        elif 'ë²ˆí˜¸' in col: rename_map[col] = 'ë²ˆí˜¸'
        elif 'ì„¸ë¶€ëŠ¥ë ¥' in col: rename_map[col] = 'ë‚´ìš©'
        elif 'íŠ¹ê¸°ì‚¬í•­' in col: rename_map[col] = 'ë‚´ìš©'
    df = df.rename(columns=rename_map)
    
    if 'ë‚´ìš©' not in df.columns or 'ê³¼ëª©/ì˜ì—­' not in df.columns: return None

    df['ë²ˆí˜¸'] = pd.to_numeric(df['ë²ˆí˜¸'], errors='coerce')
    df = df[df['ê³¼ëª©/ì˜ì—­'] != 'ê³¼ ëª©']
    df = df[df['ê³¼ëª©/ì˜ì—­'] != 'ê³¼ëª©']
    df['ë²ˆí˜¸'] = df['ë²ˆí˜¸'].ffill()
    df['ê³¼ëª©/ì˜ì—­'] = df['ê³¼ëª©/ì˜ì—­'].ffill()
    df['í•™ê¸°'] = df['í•™ê¸°'].ffill()
    
    df = df.dropna(subset=['ë²ˆí˜¸', 'ë‚´ìš©'])
    
    df_grouped = df.groupby(['ë²ˆí˜¸', 'í•™ê¸°', 'ê³¼ëª©/ì˜ì—­'])['ë‚´ìš©'].apply(lambda x: ' '.join(x.astype(str))).reset_index()
    
    df_grouped['í•™ë…„ ë°˜'] = grade_class
    df_grouped['ì‹œìˆ˜'] = '' 
    
    return df_grouped[['í•™ë…„ ë°˜', 'ë²ˆí˜¸', 'í•™ê¸°', 'ê³¼ëª©/ì˜ì—­', 'ì‹œìˆ˜', 'ë‚´ìš©']]

def process_chang(df_raw, grade_class):
    header_idx = -1
    for i, row in df_raw.iterrows():
        row_str = row.astype(str).values
        if any('ì˜' in s and 'ì—­' in s for s in row_str) and any('ì‹œ' in s and 'ê°„' in s for s in row_str):
            header_idx = i
            break
            
    if header_idx == -1: return None
    
    cols = df_raw.iloc[header_idx].fillna('').astype(str).values.tolist()
    
    if header_idx > 0:
        upper_row = df_raw.iloc[header_idx - 1].fillna('').astype(str).values.tolist()
        for i in range(len(cols)):
            if cols[i].strip() == '' or cols[i].lower() == 'nan':
                if i < len(upper_row) and upper_row[i].strip() != '' and upper_row[i].lower() != 'nan':
                    cols[i] = upper_row[i]
    
    cols = [c.replace(" ", "") for c in cols]
    
    df = df_raw.iloc[header_idx+1:].copy()
    df.columns = cols
    
    rename_map = {}
    for col in df.columns:
        if 'ë²ˆí˜¸' in col: rename_map[col] = 'ë²ˆí˜¸'
        elif 'ì˜ì—­' in col: rename_map[col] = 'ê³¼ëª©/ì˜ì—­'
        elif 'ì‹œê°„' in col: rename_map[col] = 'ì‹œìˆ˜'
        elif 'íŠ¹ê¸°ì‚¬í•­' in col: rename_map[col] = 'ë‚´ìš©'
    
    df = df.rename(columns=rename_map)
    
    if 'ë²ˆí˜¸' not in df.columns or 'ë‚´ìš©' not in df.columns or 'ê³¼ëª©/ì˜ì—­' not in df.columns:
        return None

    df['ë²ˆí˜¸'] = pd.to_numeric(df['ë²ˆí˜¸'], errors='coerce')
    df = df[df['ê³¼ëª©/ì˜ì—­'] != 'ì˜ ì—­']
    df = df[df['ê³¼ëª©/ì˜ì—­'] != 'ì˜ì—­']
    
    df['ë²ˆí˜¸'] = df['ë²ˆí˜¸'].ffill()
    df['ê³¼ëª©/ì˜ì—­'] = df['ê³¼ëª©/ì˜ì—­'].ffill()
    df['ì‹œìˆ˜'] = df['ì‹œìˆ˜'].ffill()
    df = df.dropna(subset=['ë²ˆí˜¸'])
    
    df = df[df['ë‚´ìš©'].astype(str) != 'í¬ë§ë¶„ì•¼']
    df = df[~df['ë‚´ìš©'].astype(str).str.contains('í¬ë§ë¶„ì•¼', na=False)]
    df = df.dropna(subset=['ë‚´ìš©'])

    df_grouped = df.groupby(['ë²ˆí˜¸', 'ê³¼ëª©/ì˜ì—­', 'ì‹œìˆ˜'])['ë‚´ìš©'].apply(lambda x: ' '.join(x.astype(str))).reset_index()
    
    df_grouped['í•™ë…„ ë°˜'] = grade_class
    df_grouped['í•™ê¸°'] = '' 
    
    return df_grouped[['í•™ë…„ ë°˜', 'ë²ˆí˜¸', 'í•™ê¸°', 'ê³¼ëª©/ì˜ì—­', 'ì‹œìˆ˜', 'ë‚´ìš©']]

def detect_duplicates(df):
    """ë‹¨ì¼ íŒŒì¼ ë‚´ ë³µë¶™(ì¤‘ë³µ) ë¬¸ì¥ íƒì§€"""
    sentence_pattern = re.compile(r'[^.!?]+[.!?]')
    df['ì¤‘ë³µì—¬ë¶€'] = False
    df['ë¹„ê³ (ì¤‘ë³µë¬¸ì¥)'] = ''
    df['ì¤‘ë³µë°°ê²½ìƒ‰'] = '' 
    df['ì¤‘ë³µê¸€ììƒ‰'] = ''
    
    color_pairs = [
        ('#ffe6e6', '#cc0000'), ('#e6f2ff', '#004080'), ('#e6ffe6', '#006600'),
        ('#fff2e6', '#cc6600'), ('#f2e6ff', '#4d0099'), ('#ffffe6', '#808000'),
        ('#e6ffff', '#006666'), ('#ffe6f2', '#99004d'), ('#f2ffe6', '#4d9900'),
        ('#ebebe0', '#333333')
    ]
    
    df['ê³¼ëª©/ì˜ì—­'] = df['ê³¼ëª©/ì˜ì—­'].fillna('ê¸°íƒ€')
    
    for subject, group in df.groupby('ê³¼ëª©/ì˜ì—­'):
        if len(group) < 2: continue
        
        sentence_counts = {}
        for idx, row in group.iterrows():
            content = str(row['ë‚´ìš©'])
            sentences = [s.strip() for s in sentence_pattern.findall(content)]
            for s in sentences:
                if len(s) < 10: continue
                sentence_counts[s] = sentence_counts.get(s, 0) + 1
        
        duplicate_sentences = {s for s, count in sentence_counts.items() if count > 1}
        
        color_map = {}
        for i, dup_sent in enumerate(duplicate_sentences):
            color_map[dup_sent] = color_pairs[i % len(color_pairs)]
            
        for idx, row in group.iterrows():
            content = str(row['ë‚´ìš©'])
            sentences = [s.strip() for s in sentence_pattern.findall(content)]
            found_duplicates = [s for s in sentences if s in duplicate_sentences]
            
            if found_duplicates:
                df.at[idx, 'ì¤‘ë³µì—¬ë¶€'] = True
                unique_dupes = list(set(found_duplicates))
                df.at[idx, 'ë¹„ê³ (ì¤‘ë³µë¬¸ì¥)'] = " / ".join(unique_dupes)
                
                bg_color, text_color = color_map[unique_dupes[0]]
                df.at[idx, 'ì¤‘ë³µë°°ê²½ìƒ‰'] = bg_color
                df.at[idx, 'ì¤‘ë³µê¸€ììƒ‰'] = text_color

    return df

def cross_validate_files(df1, df2, name1, name2):
    """ë‘ íŒŒì¼ ê°„ì˜ êµì°¨ ì ê²€ (ë™ì¼ ê³¼ëª© ë‚´ ì¤‘ë³µ ë¬¸ì¥ íƒìƒ‰)"""
    sentence_pattern = re.compile(r'[^.!?]+[.!?]')
    cross_results = []
    
    # ë‘ íŒŒì¼ì— ê³µí†µìœ¼ë¡œ ì¡´ì¬í•˜ëŠ” ê³¼ëª©/ì˜ì—­ ì°¾ê¸°
    subjects1 = set(df1['ê³¼ëª©/ì˜ì—­'].dropna().unique())
    subjects2 = set(df2['ê³¼ëª©/ì˜ì—­'].dropna().unique())
    common_subjects = subjects1.intersection(subjects2)
    
    for subj in common_subjects:
        group1 = df1[df1['ê³¼ëª©/ì˜ì—­'] == subj]
        group2 = df2[df2['ê³¼ëª©/ì˜ì—­'] == subj]
        
        # íŒŒì¼ 1ì˜ ë¬¸ì¥ë“¤ ìˆ˜ì§‘ (ë¬¸ì¥ -> í•™ìƒì •ë³´ ë¦¬ìŠ¤íŠ¸)
        sent_map1 = {}
        for _, row in group1.iterrows():
            content = str(row['ë‚´ìš©'])
            student_info = f"{row['í•™ë…„ ë°˜']} {row['ë²ˆí˜¸']}ë²ˆ"
            for s in [s.strip() for s in sentence_pattern.findall(content)]:
                if len(s) < 10: continue # 10ì ë¯¸ë§Œ ë¬´ì‹œ
                if s not in sent_map1: sent_map1[s] = []
                sent_map1[s].append(student_info)
                
        # íŒŒì¼ 2ì˜ ë¬¸ì¥ë“¤ ìˆ˜ì§‘
        sent_map2 = {}
        for _, row in group2.iterrows():
            content = str(row['ë‚´ìš©'])
            student_info = f"{row['í•™ë…„ ë°˜']} {row['ë²ˆí˜¸']}ë²ˆ"
            for s in [s.strip() for s in sentence_pattern.findall(content)]:
                if len(s) < 10: continue
                if s not in sent_map2: sent_map2[s] = []
                sent_map2[s].append(student_info)
                
        # êµì°¨ ì¤‘ë³µëœ ë¬¸ì¥ ì°¾ê¸° (êµì§‘í•©)
        common_sentences = set(sent_map1.keys()).intersection(set(sent_map2.keys()))
        
        # ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ (ê³¼ëª© ë‚´ì—ì„œ ë™ì¼ ë¬¸ì¥ì´ ì—¬ëŸ¬ ê°œë©´ í–‰ ì¶”ê°€)
        for s in common_sentences:
            students1 = ", ".join(list(set(sent_map1[s])))
            students2 = ", ".join(list(set(sent_map2[s])))
            cross_results.append({
                'ê³¼ëª©/ì˜ì—­': subj,
                'ë™ì¼ ë¬¸ì¥': s,
                f'ì²«ë²ˆì§¸ íŒŒì¼({name1}) í•™ìƒë°˜ ë²ˆí˜¸': students1,
                f'ë‘ë²ˆì§¸ íŒŒì¼({name2}) í•™ìƒë°˜ ë²ˆí˜¸': students2
            })
            
    if cross_results:
        return pd.DataFrame(cross_results).sort_values(by=['ê³¼ëª©/ì˜ì—­'])
    else:
        # ì¤‘ë³µì´ ì—†ì„ ê²½ìš° ë¹ˆ ë°ì´í„°í”„ë ˆì„ ë°˜í™˜
        return pd.DataFrame(columns=['ê³¼ëª©/ì˜ì—­', 'ë™ì¼ ë¬¸ì¥', f'ì²«ë²ˆì§¸ íŒŒì¼({name1}) í•™ìƒë°˜ ë²ˆí˜¸', f'ë‘ë²ˆì§¸ íŒŒì¼({name2}) í•™ìƒë°˜ ë²ˆí˜¸'])

def to_excel_multiple_sheets(df_dict, cross_df=None):
    """ì—¬ëŸ¬ ë°ì´í„°í”„ë ˆì„ê³¼ êµì°¨ì ê²€ ê²°ê³¼ë¥¼ ì—‘ì…€ì— ì €ì¥"""
    output = io.BytesIO()
    
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        for file_name, df in df_dict.items():
            safe_sheet_name = re.sub(r'[\\/*?:\[\]]', '', file_name)[:31]
            save_cols = [c for c in df.columns if c not in ['ì¤‘ë³µì—¬ë¶€', 'ì¤‘ë³µë°°ê²½ìƒ‰', 'ì¤‘ë³µê¸€ììƒ‰']]
            
            def style_duplicate_excel(row):
                styles = [''] * len(row)
                if row.get('ì¤‘ë³µì—¬ë¶€', False) and row.get('ì¤‘ë³µë°°ê²½ìƒ‰', ''):
                    bg_color = row['ì¤‘ë³µë°°ê²½ìƒ‰']
                    txt_color = row['ì¤‘ë³µê¸€ììƒ‰']
                    
                    for col in ['ê³¼ëª©/ì˜ì—­', 'ë²ˆí˜¸', 'ë‚´ìš©']:
                        if col in row.index:
                            try:
                                idx = row.index.get_loc(col)
                                styles[idx] = f'background-color: {bg_color}; color: {txt_color}; font-weight: bold;'
                            except KeyError: pass
                    
                    if 'ë¹„ê³ (ì¤‘ë³µë¬¸ì¥)' in row.index:
                        try:
                            note_idx = row.index.get_loc('ë¹„ê³ (ì¤‘ë³µë¬¸ì¥)')
                            styles[note_idx] = 'color: red;'
                        except KeyError: pass
                return styles

            styler = df.style.apply(style_duplicate_excel, axis=1)
            styler.to_excel(writer, index=False, columns=save_cols, sheet_name=safe_sheet_name)
            
            worksheet = writer.sheets[safe_sheet_name]
            for idx, col in enumerate(save_cols):
                width = 50 if 'ë‚´ìš©' in col or 'ë¹„ê³ ' in col else 12
                worksheet.column_dimensions[chr(65 + idx)].width = width
                
        # êµì°¨ ì ê²€ ê²°ê³¼ ì‹œíŠ¸ ì¶”ê°€
        if cross_df is not None and not cross_df.empty:
            cross_sheet_name = "êµì°¨ì ê²€ê²°ê³¼"
            cross_df.to_excel(writer, index=False, sheet_name=cross_sheet_name)
            worksheet = writer.sheets[cross_sheet_name]
            # ì—´ ë„ˆë¹„ ì¡°ì •
            worksheet.column_dimensions['A'].width = 15 # ê³¼ëª©/ì˜ì—­
            worksheet.column_dimensions['B'].width = 60 # ë™ì¼ ë¬¸ì¥
            worksheet.column_dimensions['C'].width = 20 # ì²«ë²ˆì§¸ íŒŒì¼ í•™ìƒ
            worksheet.column_dimensions['D'].width = 20 # ë‘ë²ˆì§¸ íŒŒì¼ í•™ìƒ

    return output.getvalue()

# -----------------------------------------------------------------------------
# 3. ë©”ì¸ ì•± UI
# -----------------------------------------------------------------------------

st.title("ğŸ« í•™ìƒë¶€ ì ê²€ ë„ìš°ë¯¸")
st.markdown("""
**ì§€ì›ë‚´ìš©:** í–‰íŠ¹, ì„¸íŠ¹(êµê³¼), ì°½ì²´(ììœ¨/ì§„ë¡œ)

**ê¸°ëŠ¥:**
  1. xlsx_data íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë° ì—…ë¡œë“œ ì‹œ **ìë™ ë¶„ë¥˜ ë° ì •ë¦¬**
  2. **ë³µë¶™ ì˜ì‹¬ ë¬¸ì¥ ê·¸ë£¹ë³„ ë°°ê²½ìƒ‰/ê¸€ììƒ‰ ë‹¤ë¥´ê²Œ í‘œì‹œ (ê³¼ëª©, ë²ˆí˜¸, ë‚´ìš© ê°•ì¡°)**
  3. **ì—¬ëŸ¬ íŒŒì¼ ì—…ë¡œë“œ ì‹œ íƒ­(Tab)ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ í‘œì‹œ**
  4. **ë‘ ê°œ ì´ìƒì˜ íŒŒì¼ ì—…ë¡œë“œ ì‹œ íŒŒì¼ ê°„ ë³µë¶™(êµì°¨ ì ê²€) ìë™ íƒì§€** ğŸš€
""")

uploaded_files = st.file_uploader(
    "ì²˜ë¦¬í•  íŒŒì¼ë“¤ì„ ëª¨ë‘ ì˜¬ë ¤ì£¼ì„¸ìš”", 
    accept_multiple_files=True,
    type=['xlsx', 'xls', 'csv']
)

if uploaded_files:
    processed_data_dict = {}
    
    with st.status("íŒŒì¼ ë¶„ì„ ë° ì²˜ë¦¬ ì¤‘...", expanded=True) as status:
        for file in uploaded_files:
            df_raw = load_data(file)
            if df_raw is None:
                continue
                
            grade_class = extract_grade_class(df_raw)
            file_type = detect_file_type(df_raw)
            
            processed_df = None
            type_label = ""
            
            if file_type == 'HANG':
                processed_df = process_hang(df_raw, grade_class)
                type_label = "í–‰ë™íŠ¹ì„±"
            elif file_type == 'KYO':
                processed_df = process_kyo(df_raw, grade_class)
                type_label = "ì„¸ë¶€ëŠ¥ë ¥"
            elif file_type == 'CHANG':
                processed_df = process_chang(df_raw, grade_class)
                type_label = "ì°½ì˜ì ì²´í—˜"
            else:
                st.warning(f"âš ï¸ {file.name}: ì•Œ ìˆ˜ ì—†ëŠ” í˜•ì‹ (ê±´ë„ˆëœ€)")
                continue
                
            if processed_df is not None and not processed_df.empty:
                processed_df = processed_df.sort_values(by=['ê³¼ëª©/ì˜ì—­', 'ë²ˆí˜¸'])
                processed_df = detect_duplicates(processed_df)
                processed_df['ë²ˆí˜¸'] = pd.to_numeric(processed_df['ë²ˆí˜¸']).astype(int)
                
                ordered_cols = ['í•™ë…„ ë°˜', 'í•™ê¸°', 'ê³¼ëª©/ì˜ì—­', 'ë²ˆí˜¸', 'ì‹œìˆ˜', 'ë‚´ìš©', 'ë¹„ê³ (ì¤‘ë³µë¬¸ì¥)', 'ì¤‘ë³µì—¬ë¶€', 'ì¤‘ë³µë°°ê²½ìƒ‰', 'ì¤‘ë³µê¸€ììƒ‰']
                processed_df = processed_df[ordered_cols]
                
                processed_data_dict[file.name] = processed_df
                st.write(f"âœ… {file.name} ({type_label} / {grade_class}) - {len(processed_df)}ëª… ì²˜ë¦¬")

        status.update(label="ëª¨ë“  íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ!", state="complete", expanded=False)

    if processed_data_dict:
        st.divider()
        st.subheader("ğŸ“Š ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°")
        
        # êµì°¨ ì ê²€ ë¡œì§ ì‹¤í–‰ (íŒŒì¼ì´ 2ê°œ ì´ìƒì¼ ë•Œ, ì²˜ìŒ ë‘ íŒŒì¼ ê¸°ì¤€)
        cross_df = None
        file_names = list(processed_data_dict.keys())
        
        if len(file_names) >= 2:
            name1, name2 = file_names[0], file_names[1]
            df1, df2 = processed_data_dict[name1], processed_data_dict[name2]
            cross_df = cross_validate_files(df1, df2, name1, name2)
            
        # íƒ­ êµ¬ì„± (íŒŒì¼ë³„ íƒ­ + êµì°¨ì ê²€ íƒ­)
        tab_names = file_names.copy()
        if cross_df is not None:
            tab_names.append("ğŸš¨ êµì°¨ ì ê²€ ê²°ê³¼")
            
        tabs = st.tabs(tab_names)
        
        def highlight_row_web(row):
            styles = [''] * len(row)
            if row.get('ì¤‘ë³µì—¬ë¶€', False) and row.get('ì¤‘ë³µë°°ê²½ìƒ‰', ''):
                bg_color = row['ì¤‘ë³µë°°ê²½ìƒ‰']
                txt_color = row['ì¤‘ë³µê¸€ììƒ‰']
                for col in ['ê³¼ëª©/ì˜ì—­', 'ë²ˆí˜¸', 'ë‚´ìš©']:
                    if col in row.index:
                        try:
                            idx = row.index.get_loc(col)
                            styles[idx] = f'background-color: {bg_color}; color: {txt_color}; font-weight: bold;'
                        except KeyError: pass
            return styles
        
        # íƒ­ ì½˜í…ì¸  ì±„ìš°ê¸°
        for i, tab in enumerate(tabs):
            with tab:
                if i < len(file_names):
                    # ê°œë³„ íŒŒì¼ íƒ­
                    file_name = file_names[i]
                    df_to_show = processed_data_dict[file_name]
                    st.dataframe(
                        df_to_show.style.apply(highlight_row_web, axis=1),
                        column_config={
                            "ì‹œìˆ˜": st.column_config.TextColumn("ì‹œìˆ˜", width="small"),
                            "ë¹„ê³ (ì¤‘ë³µë¬¸ì¥)": st.column_config.TextColumn("âš ï¸ ë³µë¶™ ì˜ì‹¬ ë¬¸ì¥", width="medium"),
                            "ì¤‘ë³µì—¬ë¶€": None, "ì¤‘ë³µë°°ê²½ìƒ‰": None, "ì¤‘ë³µê¸€ììƒ‰": None
                        },
                        use_container_width=True
                    )
                else:
                    # êµì°¨ ì ê²€ ê²°ê³¼ íƒ­
                    if cross_df is not None and not cross_df.empty:
                        st.warning(f"âš ï¸ {name1} ê³¼(ì™€) {name2} ì‚¬ì´ì— ë‚´ìš©ì´ ì¤‘ë³µëœ ë¬¸ì¥ë“¤ì…ë‹ˆë‹¤.")
                        st.dataframe(
                            cross_df,
                            column_config={
                                "ë™ì¼ ë¬¸ì¥": st.column_config.TextColumn("ë™ì¼ ë¬¸ì¥", width="large"),
                                f"ì²«ë²ˆì§¸ íŒŒì¼({name1}) í•™ìƒë°˜ ë²ˆí˜¸": st.column_config.TextColumn(f"{name1} í•™ìƒ", width="medium"),
                                f"ë‘ë²ˆì§¸ íŒŒì¼({name2}) í•™ìƒë°˜ ë²ˆí˜¸": st.column_config.TextColumn(f"{name2} í•™ìƒ", width="medium")
                            },
                            use_container_width=True
                        )
                    else:
                        st.success("ğŸ‰ ë‘ íŒŒì¼ ì‚¬ì´ì— êµì°¨ ì¤‘ë³µëœ ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤!")
        
        st.divider()
        excel_data = to_excel_multiple_sheets(processed_data_dict, cross_df=cross_df)
        
        st.download_button(
            label="ğŸ“¥ í†µí•© ì—‘ì…€ ë‹¤ìš´ë¡œë“œ (ê°œë³„ì‹œíŠ¸ + êµì°¨ì ê²€ì‹œíŠ¸ í¬í•¨)",
            data=excel_data,
            file_name="ìƒê¸°ë¶€_ì •ë¦¬ê²°ê³¼_ì „ì²´.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
    else:
        st.info("ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
